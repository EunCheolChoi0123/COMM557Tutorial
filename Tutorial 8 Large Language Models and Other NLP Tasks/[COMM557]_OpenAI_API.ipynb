{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the setup"
      ],
      "metadata": {
        "id": "fJ4JAfmuPJC7"
      },
      "id": "fJ4JAfmuPJC7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH_8WwX1xofy",
        "outputId": "a007e39e-2128-4319-d42f-75d84b3ecdf2"
      },
      "id": "UH_8WwX1xofy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First, let's look at how OpenAI models tokenize text.\n",
        "- This is important, because you pay-per-token.\n",
        "- Pricing: https://openai.com/pricing\n",
        "- Also, context size matters. Although nowadays OpenAI models are capable of handling long chat (for gpt-4o, ~128k tokens), it forgets past things if it gets too long.\n",
        "- https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"
      ],
      "metadata": {
        "id": "V-N_jB2AvaF9"
      },
      "id": "V-N_jB2AvaF9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmyre9bwy3bt",
        "outputId": "f4a70c9f-81fa-48da-9873-9483a2331774"
      },
      "id": "Xmyre9bwy3bt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "JLxQfc7l_BE2"
      },
      "id": "JLxQfc7l_BE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-4.1\")"
      ],
      "metadata": {
        "id": "HpWfewNv_GGa"
      },
      "id": "HpWfewNv_GGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.encode(\"tiktoken is great!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snjifIKy_JHT",
        "outputId": "63deb1b6-6bfb-41cb-fa0b-8a4f6456aad0"
      },
      "id": "snjifIKy_JHT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[83, 8251, 2488, 382, 2212, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ],
      "metadata": {
        "id": "t5cGHV7I_OX1"
      },
      "id": "t5cGHV7I_OX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string(\"tiktoken is great!\", \"gpt-4.1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifesPjpw_PLT",
        "outputId": "697b454d-3315-4172-dc03-36dab63d66c7"
      },
      "id": "ifesPjpw_PLT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[encoding.decode_single_token_bytes(token) for token in encoding.encode(\"tiktoken is great!\")]\n",
        "\n",
        "# b indicates byte-strings. For more info: https://stackoverflow.com/questions/6224052/what-is-the-difference-between-a-string-and-a-byte-string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "019LZnkO_ivc",
        "outputId": "5c99f8e5-b9ff-46ff-865a-c653cbef6872"
      },
      "id": "019LZnkO_ivc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b't', b'ikt', b'oken', b' is', b' great', b'!']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basically, gpt-4o, gpt-4o-mini, etc. are chat models.\n",
        "- Models look at previous dialogues, and return their answer."
      ],
      "metadata": {
        "id": "C2DU2cJAue_B"
      },
      "id": "C2DU2cJAue_B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f69062-8bbb-4fe6-8e59-1e8e29a5601a",
      "metadata": {
        "id": "67f69062-8bbb-4fe6-8e59-1e8e29a5601a"
      },
      "outputs": [],
      "source": [
        "# https://platform.openai.com/api-keys\n",
        "key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=key,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who cheerfully answers to the user.\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'm so hungry.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"No wonder you are hungry. It's already past one.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Oh my goodness. Already? What should we eat for lunch?\"},\n",
        "    ],\n",
        "    model=\"gpt-4.1-mini\",\n",
        ")"
      ],
      "metadata": {
        "id": "iqUYsNzixadz"
      },
      "id": "iqUYsNzixadz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgugkI6-n6LT",
        "outputId": "c6054105-a020-4ec9-cf33-4af2e3f83167"
      },
      "id": "JgugkI6-n6LT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-CQpa654SWAV38lGvFr6DCIOQgfoRc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='How about something quick and tasty? Maybe a sandwich with your favorite fillings, a fresh salad, or some pasta? If you’re in the mood to cook, I can help you find a simple recipe too! What are you craving?', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1760510842, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_c064fdde7c', usage=CompletionUsage(completion_tokens=47, prompt_tokens=60, total_tokens=107, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MgXIzcwIyRpF",
        "outputId": "29d635a6-0e63-4148-d2b2-f19abb2e7957"
      },
      "id": "MgXIzcwIyRpF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How about something quick and tasty? Maybe a sandwich with your favorite fillings, a fresh salad, or some pasta? If you’re in the mood to cook, I can help you find a simple recipe too! What are you craving?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# However, it's versatile. It can be used to generate convincing text.\n",
        "- that refutes false claims https://arxiv.org/pdf/2310.09223.pdf"
      ],
      "metadata": {
        "id": "GvDFvzpDPgzx"
      },
      "id": "GvDFvzpDPgzx"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(system, user, model=\"gpt-4.1-mini\", temperature=0, max_tokens=256, key=key):\n",
        "    client = OpenAI(\n",
        "        api_key=key,\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "        ],\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "A2O3VVpt0aK_"
      },
      "id": "A2O3VVpt0aK_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Claim debunked: https://toolbox.google.com/factcheck/explorer/search/vaccinated%20individuals%20emit%20Bluetooth%20signals;hl=en\n",
        "\n",
        "system = 'Generate a social media post so that it successfully refutes the claim provided.'\n",
        "user = 'Claim: Vaccinated people emit Bluetooth signals.'\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "Yeys7hS26ryi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b0a6b3-16b3-45bb-9048-b82ada6af3d5"
      },
      "id": "Yeys7hS26ryi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚨 Myth Buster Alert! 🚨\n",
            "\n",
            "There’s a bizarre claim going around that vaccinated people emit Bluetooth signals. Let’s set the record straight: **Vaccines do NOT contain any technology that can emit Bluetooth or any other wireless signals.** \n",
            "\n",
            "Vaccines are made to protect your health by training your immune system — they don’t have microchips, trackers, or transmitters. Bluetooth signals come from electronic devices like phones and speakers, not from your body.\n",
            "\n",
            "Stay informed, trust science, and don’t fall for misinformation! 💉✨ #VaccinesWork #ScienceMatters #MythBusting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annotation capabilities are explored as well.\n",
        "- Might not perform as well as carefully fine-tuned models https://www.sciencedirect.com/science/article/pii/S156625352300177X\n",
        "- The performance heavily relies on what models you use, and what prompts you enter https://arxiv.org/pdf/2310.09223.pdf"
      ],
      "metadata": {
        "id": "wK4msLoWXDMv"
      },
      "id": "wK4msLoWXDMv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt from Kocon et al., 2023, example from Choi & Ferrara, 2024\n",
        "\n",
        "system = 'Describe the sentiment of the given text. Choose your answer from provided list and map your answer with following negative: 0, neutral: 1, positive: 2 and return an integer.'\n",
        "user = \"\"\"Text: omg my dad got vaccinated yesterday and I just connected him to bluetooth\n",
        "Possible sentiment: negative, neutral, positive\"\"\"\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "-GNGH52elr7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939240b7-e4f0-40ba-be33-f4f565c96dcb"
      },
      "id": "-GNGH52elr7y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the given text is positive. The speaker expresses excitement about their dad getting vaccinated and connects it to a humorous or light-hearted action of connecting him to Bluetooth. Therefore, the answer is 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stance detection prompt, slightly edited from Choi & Ferrara, 2025\n",
        "\n",
        "system = \"\"\"Which of the following best describe the relationship between TWEET and CLAIM: agreement, disagreement, or neutral? Explain why and give me the final answer.\"\"\"\n",
        "user = \"\"\"TWEET: It's so strange to see people believing vaccination makes you connect to your phone #VaccineFacts\n",
        "CLAIM: Vaccininated people emit Bluetooth signals.\n",
        "ANSWER: Let's think step by step.\"\"\"\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHWqFDl_59db",
        "outputId": "e17ab8df-e3ab-4e71-e38c-15d35808c280"
      },
      "id": "yHWqFDl_59db",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To analyze the relationship between the TWEET and the CLAIM, we can break it down as follows:\n",
            "\n",
            "1. **Understanding the TWEET**: The TWEET expresses skepticism or disbelief regarding the idea that vaccination has any connection to technology, specifically that it allows people to connect to their phones. The use of the phrase \"It's so strange to see people believing\" indicates that the author finds this belief to be irrational or unfounded.\n",
            "\n",
            "2. **Understanding the CLAIM**: The CLAIM states that vaccinated people emit Bluetooth signals, which implies a direct connection between vaccination and the ability to connect to devices wirelessly. This is a specific assertion that suggests a technological effect of vaccination.\n",
            "\n",
            "3. **Analyzing the Relationship**: The TWEET and the CLAIM are fundamentally at odds. The TWEET dismisses the idea that vaccination has any technological implications, while the CLAIM asserts that there is a direct effect of vaccination on technology (i.e., emitting Bluetooth signals). \n",
            "\n",
            "4. **Conclusion**: Since the TWEET expresses disbelief in the notion presented in the CLAIM, the relationship between them is one of disagreement.\n",
            "\n",
            "Final Answer: Disagreement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning a score\n",
        "\n",
        "system = \"\"\"From a score of 1 to 5, how much are TWEET and CLAIM related to one another? Explain why and give me the final answer.\"\"\"\n",
        "user = \"\"\"TWEET: It's so strange to see people believing vaccination makes you connect to your phone #VaccineFacts\n",
        "CLAIM: Vaccininated people emit Bluetooth signals.\n",
        "ANSWER: Let's think step by step.\"\"\"\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXx3L7_A6PF7",
        "outputId": "405a412f-9964-4fe8-b5e2-7d88be56224e"
      },
      "id": "gXx3L7_A6PF7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To evaluate the relationship between TWEET and CLAIM, we can analyze the content and context of both statements.\n",
            "\n",
            "1. **Content Analysis**:\n",
            "   - The TWEET expresses skepticism about a belief that vaccination connects individuals to their phones, using the hashtag #VaccineFacts. It implies that the idea is strange or unfounded.\n",
            "   - The CLAIM states that vaccinated people emit Bluetooth signals, which is a specific assertion that aligns with the skepticism expressed in the TWEET.\n",
            "\n",
            "2. **Contextual Relationship**:\n",
            "   - Both the TWEET and the CLAIM are related to the topic of vaccination and the misconceptions surrounding it. The TWEET critiques a belief that is likely based on misinformation, while the CLAIM presents a specific example of such misinformation.\n",
            "\n",
            "3. **Degree of Relation**:\n",
            "   - The TWEET directly addresses the absurdity of the CLAIM, indicating that they are closely related. The TWEET serves as a commentary on the type of claims that circulate regarding vaccinations, including the one made in the CLAIM.\n",
            "\n",
            "Based on this analysis, I would rate the relationship between TWEET and CLAIM as a **4**. They are closely related, as the TWEET critiques the very notion presented in the CLAIM, but they are not identical in nature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can be creative,\n",
        "- but also remember not to rely too much on them because they tend to err\n",
        "- for annotation and classification tasks, I recommend you to carefully compare the results with different methods\n",
        "- for generative tasks, at least read the results for yourselves."
      ],
      "metadata": {
        "id": "tSO_7_cl89cv"
      },
      "id": "tSO_7_cl89cv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On Your Own\n",
        "- Try to Prompt-Engineer the task you want to try out!"
      ],
      "metadata": {
        "id": "47CLqyQ28MFB"
      },
      "id": "47CLqyQ28MFB"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}