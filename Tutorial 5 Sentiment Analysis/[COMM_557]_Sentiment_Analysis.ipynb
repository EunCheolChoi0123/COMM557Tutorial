{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZeEg-28vZob"
      },
      "source": [
        "### Sentiment Analysis\n",
        "#### TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfK31UX0A-Zm",
        "outputId": "0d1e103e-d8e3-4a42-965f-176d7df1962c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.12/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from vaderSentiment) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->vaderSentiment) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentiment analysis\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "96YnHkOZAySO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('brown')\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmn3htnsy9uu",
        "outputId": "5979068d-a3c9-40fc-cc3c-858d369e524b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post = \"Our analysis shows concerted efforts by coordinated accounts to disseminate misleading, redundant, biased, and AI-generated content through a cross-platform information operation. The network spans X and YouTube, disseminating political content through duplicated mock news sites.\""
      ],
      "metadata": {
        "id": "LY0NSt9tBTUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p22_oBbdvZob"
      },
      "outputs": [],
      "source": [
        "blob = TextBlob(post)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RUx-kd_vZob",
        "outputId": "af88e332-5dce-45fc-bcba-43f37eaa7f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['Our', 'analysis', 'shows', 'concerted', 'efforts', 'by', 'coordinated', 'accounts', 'to', 'disseminate', 'misleading', ',', 'redundant', ',', 'biased', ',', 'and', 'AI-generated', 'content', 'through', 'a', 'cross-platform', 'information', 'operation', '.', 'The', 'network', 'spans', 'X', 'and', 'YouTube', ',', 'disseminating', 'political', 'content', 'through', 'duplicated', 'mock', 'news', 'sites', '.'])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# TextBlob provides basic nlp functions\n",
        "# Tokenizing a sentence\n",
        "blob.tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbh3kSQmvZob",
        "outputId": "88a1982b-b2b9-405f-8ab2-c571f76818db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Our', 'PRP$'),\n",
              " ('analysis', 'NN'),\n",
              " ('shows', 'VBZ'),\n",
              " ('concerted', 'VBN'),\n",
              " ('efforts', 'NNS'),\n",
              " ('by', 'IN'),\n",
              " ('coordinated', 'JJ'),\n",
              " ('accounts', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('disseminate', 'VB'),\n",
              " ('misleading', 'NN'),\n",
              " ('redundant', 'NN'),\n",
              " ('biased', 'VBN'),\n",
              " ('and', 'CC'),\n",
              " ('AI-generated', 'JJ'),\n",
              " ('content', 'NN'),\n",
              " ('through', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('cross-platform', 'JJ'),\n",
              " ('information', 'NN'),\n",
              " ('operation', 'NN'),\n",
              " ('The', 'DT'),\n",
              " ('network', 'NN'),\n",
              " ('spans', 'NNS'),\n",
              " ('X', 'VBP'),\n",
              " ('and', 'CC'),\n",
              " ('YouTube', 'NNP'),\n",
              " ('disseminating', 'VBG'),\n",
              " ('political', 'JJ'),\n",
              " ('content', 'NN'),\n",
              " ('through', 'IN'),\n",
              " ('duplicated', 'VBN'),\n",
              " ('mock', 'NN'),\n",
              " ('news', 'NN'),\n",
              " ('sites', 'NNS')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "# POS tagging\n",
        "blob.tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY_OwmEhvZoc",
        "outputId": "8980f5b5-9f70-4f81-9536-b3f278650481"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['analysis shows', 'ai-generated', 'cross-platform information operation', 'network spans', 'youtube', 'political content', 'mock news sites'])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Let's only filter nouns using blob\n",
        "blob.noun_phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzjeOYb9vZoc",
        "outputId": "aa46cf19-2c1d-4e68-9cb6-c81b3d1cf5ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# count how many times 'youtube' appear in the sentence\n",
        "blob.words.count('youtube')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TextBlob by default implements dictionary-based sentiment analysis\n",
        "# \"By default, it calculates average polarity and subjectivity over each word in a given text using a dictionary of adjectives and their hand-tagged scores.\"\n",
        "# https://stackoverflow.com/questions/43688542/textblob-sentiment-algorithm (the first answer is partially wrong)\n",
        "blob.sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdC8_kBFFIH_",
        "outputId": "67bb94d6-561e-4863-f607-183df5dbb6ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=-0.1, subjectivity=0.15000000000000002)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXHTftOGvZob"
      },
      "source": [
        "Textblob sentiment output:\n",
        "\n",
        "Polarity in [-1, 1] := [most negative, most positive]\n",
        "\n",
        "Subjectivity in [0, 1] := [factual, personal opinion]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_fhJqqqvZoc"
      },
      "outputs": [],
      "source": [
        "# let's try other sentences\n",
        "test_msg1 = 'this is not the best football team'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "502RkgyjvZoc",
        "outputId": "55f86d08-5a68-4f7b-b883-7c33ff0d4711"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=1.0, subjectivity=0.3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "blob = TextBlob(test_msg1)\n",
        "blob.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8d3PXjYvZoc"
      },
      "outputs": [],
      "source": [
        "test_msg2 = 'hey this is not too bad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqgUbuZPvZoc",
        "outputId": "05138f4c-0973-4872-b74d-c1a41d6cadfc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "blob = TextBlob(test_msg2)\n",
        "blob.sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXoH5fBavZoc",
        "outputId": "59787802-d756-41f2-9bc9-53b8c3852b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is not the best football team\n",
            "Sentiment(classification='neg', p_pos=0.41870201702509297, p_neg=0.5812979829749073)\n",
            "hey this is not too bad\n",
            "Sentiment(classification='neg', p_pos=0.21032203786065207, p_neg=0.7896779621393482)\n"
          ]
        }
      ],
      "source": [
        "# NaiveBayesAnalyzer option, trained on movie reviews\n",
        "# https://www.dataquest.io/blog/naive-bayes-tutorial/\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "\n",
        "print(test_msg1)\n",
        "blob = TextBlob(test_msg1, analyzer=NaiveBayesAnalyzer())\n",
        "print(blob.sentiment)\n",
        "\n",
        "print(test_msg2)\n",
        "blob = TextBlob(test_msg2, analyzer=NaiveBayesAnalyzer())\n",
        "print(blob.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzMOQMfmvZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02eea9ec-0cd8-4b97-9fcf-8dc9ad309068"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentiment(classification='pos', p_pos=0.9975511715073467, p_neg=0.002448828492648301)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "blob = TextBlob(post, analyzer=NaiveBayesAnalyzer())\n",
        "blob.sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDtZxt5mvZoc"
      },
      "source": [
        "Train your own classifers:\n",
        "https://textblob.readthedocs.io/en/dev/api_reference.html#module-textblob.classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sz4-6YavZoc"
      },
      "source": [
        "#### VADER (Valence Aware Dictionary and Sentiment Reasoner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6raNOUfvZoc"
      },
      "outputs": [],
      "source": [
        "# sentiment vader\n",
        "# dictionary-based, with rule-based adjustments\n",
        "analyser = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKwDz3bJvZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26be5a6e-3fab-4439-85bb-a8de1d22658c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method polarity_scores in module vaderSentiment.vaderSentiment:\n",
            "\n",
            "polarity_scores(text) method of vaderSentiment.vaderSentiment.SentimentIntensityAnalyzer instance\n",
            "    Return a float for sentiment strength based on the input text.\n",
            "    Positive values are positive valence, negative value are negative\n",
            "    valence.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(analyser.polarity_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnRuhpwtvZoc"
      },
      "source": [
        "Compound scores in [-1, 1] := [most negative, most positive]\n",
        "\n",
        "neg, neu, pos in [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "mk3IgT0YvZoc",
        "outputId": "c0de9898-4d68-4ec4-da43-042f70d0907d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.654, 'pos': 0.346, 'compound': 0.5719}\n"
          ]
        }
      ],
      "source": [
        "sentiment = analyser.polarity_scores('This is an example of a happy post')\n",
        "print(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwaGrrhYvZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848aa9e3-7bda-431a-d822-4759b6312abc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "sentiment['neg'] + sentiment['neu'] + sentiment['pos']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD2CM_0-vZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db9a300f-c033-4105-e1d6-7e5866ae4949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.6114}\n"
          ]
        }
      ],
      "source": [
        "# impact of punctuation\n",
        "sentiment = analyser.polarity_scores('This is an example of a happy post!')\n",
        "print(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHGIRIYCvZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c98e098-6388-4162-85b5-3e9220cd109f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'neg': 0.0, 'neu': 0.65, 'pos': 0.35, 'compound': 0.7901}\n"
          ]
        }
      ],
      "source": [
        "# impact of emoji\n",
        "sentiment = analyser.polarity_scores('This is an example of a happy 😁 ❤️ post! ')\n",
        "print(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HlduuJQvZoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da0bb5d-7670-405a-891e-c47b724d939a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is not the best football team\n",
            "{'neg': 0.36, 'neu': 0.64, 'pos': 0.0, 'compound': -0.5216}\n",
            "hey this is not too bad\n",
            "{'neg': 0.0, 'neu': 0.637, 'pos': 0.363, 'compound': 0.431}\n"
          ]
        }
      ],
      "source": [
        "print(test_msg1)\n",
        "sentiment = analyser.polarity_scores(test_msg1)\n",
        "print(sentiment)\n",
        "\n",
        "print(test_msg2)\n",
        "sentiment = analyser.polarity_scores(test_msg2)\n",
        "print(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(post)\n",
        "sentiment = analyser.polarity_scores(post)\n",
        "print(sentiment)"
      ],
      "metadata": {
        "id": "ZHoLmWIXFnLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c520bf42-56f6-48a3-8bd7-b5e0417ca529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our analysis shows concerted efforts by coordinated accounts to disseminate misleading, redundant, biased, and AI-generated content through a cross-platform information operation. The network spans X and YouTube, disseminating political content through duplicated mock news sites.\n",
            "{'neg': 0.192, 'neu': 0.808, 'pos': 0.0, 'compound': -0.765}\n"
          ]
        }
      ]
    }
  ]
}