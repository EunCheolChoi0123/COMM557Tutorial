{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing the setup"
      ],
      "metadata": {
        "id": "fJ4JAfmuPJC7"
      },
      "id": "fJ4JAfmuPJC7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH_8WwX1xofy",
        "outputId": "e710cc12-26a4-49f6-d5f8-aad993d7dbe9"
      },
      "id": "UH_8WwX1xofy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.51.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.51.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 jiter-0.6.0 openai-1.51.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First, let's look at how OpenAI models tokenize text.\n",
        "- This is important, because you pay-per-token.\n",
        "- Pricing: https://openai.com/pricing\n",
        "- Also, context size matters. Although nowadays OpenAI models are capable of handling long chat (for gpt-4o, ~128k tokens), it forgets past things if it gets too long.\n",
        "- https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"
      ],
      "metadata": {
        "id": "V-N_jB2AvaF9"
      },
      "id": "V-N_jB2AvaF9"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmyre9bwy3bt",
        "outputId": "2668d22d-7fc2-449c-dc0d-cf333c98fdea"
      },
      "id": "Xmyre9bwy3bt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "JLxQfc7l_BE2"
      },
      "id": "JLxQfc7l_BE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.encoding_for_model(\"gpt-4o\")"
      ],
      "metadata": {
        "id": "HpWfewNv_GGa"
      },
      "id": "HpWfewNv_GGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding.encode(\"tiktoken is great!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snjifIKy_JHT",
        "outputId": "1ded866a-8214-4e2e-ebcb-f274f9c259a6"
      },
      "id": "snjifIKy_JHT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[83, 8251, 2488, 382, 2212, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(model_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens"
      ],
      "metadata": {
        "id": "t5cGHV7I_OX1"
      },
      "id": "t5cGHV7I_OX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string(\"tiktoken is great!\", \"gpt-4o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifesPjpw_PLT",
        "outputId": "3036204e-65d6-43de-cc5f-ec87d52565d0"
      },
      "id": "ifesPjpw_PLT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[encoding.decode_single_token_bytes(token) for token in encoding.encode(\"tiktoken is great!\")]\n",
        "\n",
        "# b indicates byte-strings. For more info: https://stackoverflow.com/questions/6224052/what-is-the-difference-between-a-string-and-a-byte-string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "019LZnkO_ivc",
        "outputId": "8c7acfca-aa49-4d67-e48b-aed2a6e6faba"
      },
      "id": "019LZnkO_ivc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b't', b'ikt', b'oken', b' is', b' great', b'!']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basically, gpt-4o, gpt-4o-mini, etc. are chat models.\n",
        "- Models look at previous dialogues, and return their answer."
      ],
      "metadata": {
        "id": "C2DU2cJAue_B"
      },
      "id": "C2DU2cJAue_B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f69062-8bbb-4fe6-8e59-1e8e29a5601a",
      "metadata": {
        "id": "67f69062-8bbb-4fe6-8e59-1e8e29a5601a"
      },
      "outputs": [],
      "source": [
        "# https://platform.openai.com/api-keys\n",
        "key = \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=key,\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant who cheerfully answers to the user.\"},\n",
        "    {\"role\": \"user\", \"content\": \"I'm so hungry.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"No wonder you are hungry. It's already past one.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Oh my goodness. Already? What should we eat for lunch?\"},\n",
        "    ],\n",
        "    model=\"gpt-4o-mini\",\n",
        ")"
      ],
      "metadata": {
        "id": "iqUYsNzixadz"
      },
      "id": "iqUYsNzixadz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "MgXIzcwIyRpF",
        "outputId": "8ca749e1-926c-4264-9f82-389f35bc9d94"
      },
      "id": "MgXIzcwIyRpF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There are so many delicious options! Do you feel like something light, like a salad or a sandwich, or maybe something heartier like pasta or a warm bowl of soup? If you want to try something different, how about tacos or a grain bowl? What are you in the mood for?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# However, it's versatile. It can be used to generate convincing text.\n",
        "- that refutes false claims https://arxiv.org/pdf/2310.09223.pdf"
      ],
      "metadata": {
        "id": "GvDFvzpDPgzx"
      },
      "id": "GvDFvzpDPgzx"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(system, user, model=\"gpt-4o-mini\", temperature=0, max_tokens=256, key=key):\n",
        "    client = OpenAI(\n",
        "        api_key=key,\n",
        "    )\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        messages=[\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "        ],\n",
        "        model=model,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "A2O3VVpt0aK_"
      },
      "id": "A2O3VVpt0aK_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Claim debunked: https://toolbox.google.com/factcheck/explorer/search/vaccinated%20individuals%20emit%20Bluetooth%20signals;hl=en\n",
        "\n",
        "system = 'Generate a social media post so that it successfully refutes the claim provided.'\n",
        "user = 'Claim: Vaccinated people emit Bluetooth signals.'\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "Yeys7hS26ryi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dc8c62a-b712-4cb6-eb1c-6dc39d7e7e2e"
      },
      "id": "Yeys7hS26ryi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚫🔍 Let's set the record straight! The claim that vaccinated people emit Bluetooth signals is completely FALSE. Vaccines work by training our immune system to recognize and fight off viruses, not by turning us into walking Wi-Fi hotspots! \n",
            "\n",
            "Bluetooth technology requires specific hardware and software to function, which is NOT present in any vaccine. This misinformation can lead to unnecessary fear and confusion. \n",
            "\n",
            "Let’s focus on the facts: Vaccines save lives and protect our communities. Stay informed, stay safe, and let’s support each other with accurate information! 💉❤️ #VaccinesWork #FactCheck #StayInformed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Annotation capabilities are explored as well.\n",
        "- Might not perform as well as carefully fine-tuned models https://www.sciencedirect.com/science/article/pii/S156625352300177X\n",
        "- The performance heavily relies on what models you use, and what prompts you enter https://arxiv.org/pdf/2310.09223.pdf"
      ],
      "metadata": {
        "id": "wK4msLoWXDMv"
      },
      "id": "wK4msLoWXDMv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt from Kocon et al., 2023, example from Choi & Ferrara, 2024\n",
        "\n",
        "system = 'Describe the sentiment of the given text. Choose your answer from provided list and map your answer with following negative: 0, neutral: 1, positive: 2 and return an integer.'\n",
        "user = \"\"\"Text: omg my dad got vaccinated yesterday and I just connected him to bluetooth\n",
        "Possible sentiment: negative, neutral, positive\"\"\"\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "-GNGH52elr7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939240b7-e4f0-40ba-be33-f4f565c96dcb"
      },
      "id": "-GNGH52elr7y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the given text is positive. The speaker expresses excitement about their dad getting vaccinated and connects it to a humorous or light-hearted action of connecting him to Bluetooth. Therefore, the answer is 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stance detection prompt, slightly edited from Choi & Ferrara, 2024\n",
        "\n",
        "system = \"\"\"Which of the following best describe the relationship between TWEET and CLAIM: agreement, disagreement, or neutral? Explain why and give me the final answer.\"\"\"\n",
        "user = \"\"\"TWEET: It's so strange to see people believing vaccination makes you connect to your phone #VaccineFacts\n",
        "CLAIM: Vaccininated people emit Bluetooth signals.\n",
        "ANSWER: Let's think step by step.\"\"\"\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHWqFDl_59db",
        "outputId": "e17ab8df-e3ab-4e71-e38c-15d35808c280"
      },
      "id": "yHWqFDl_59db",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To analyze the relationship between the TWEET and the CLAIM, we can break it down as follows:\n",
            "\n",
            "1. **Understanding the TWEET**: The TWEET expresses skepticism or disbelief regarding the idea that vaccination has any connection to technology, specifically that it allows people to connect to their phones. The use of the phrase \"It's so strange to see people believing\" indicates that the author finds this belief to be irrational or unfounded.\n",
            "\n",
            "2. **Understanding the CLAIM**: The CLAIM states that vaccinated people emit Bluetooth signals, which implies a direct connection between vaccination and the ability to connect to devices wirelessly. This is a specific assertion that suggests a technological effect of vaccination.\n",
            "\n",
            "3. **Analyzing the Relationship**: The TWEET and the CLAIM are fundamentally at odds. The TWEET dismisses the idea that vaccination has any technological implications, while the CLAIM asserts that there is a direct effect of vaccination on technology (i.e., emitting Bluetooth signals). \n",
            "\n",
            "4. **Conclusion**: Since the TWEET expresses disbelief in the notion presented in the CLAIM, the relationship between them is one of disagreement.\n",
            "\n",
            "Final Answer: Disagreement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning a score\n",
        "\n",
        "system = \"\"\"From a score of 1 to 5, how much are TWEET and CLAIM related to one another? Explain why and give me the final answer.\"\"\"\n",
        "user = \"\"\"TWEET: It's so strange to see people believing vaccination makes you connect to your phone #VaccineFacts\n",
        "CLAIM: Vaccininated people emit Bluetooth signals.\n",
        "ANSWER: Let's think step by step.\"\"\"\n",
        "output = generate_text(system, user)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXx3L7_A6PF7",
        "outputId": "405a412f-9964-4fe8-b5e2-7d88be56224e"
      },
      "id": "gXx3L7_A6PF7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To evaluate the relationship between TWEET and CLAIM, we can analyze the content and context of both statements.\n",
            "\n",
            "1. **Content Analysis**:\n",
            "   - The TWEET expresses skepticism about a belief that vaccination connects individuals to their phones, using the hashtag #VaccineFacts. It implies that the idea is strange or unfounded.\n",
            "   - The CLAIM states that vaccinated people emit Bluetooth signals, which is a specific assertion that aligns with the skepticism expressed in the TWEET.\n",
            "\n",
            "2. **Contextual Relationship**:\n",
            "   - Both the TWEET and the CLAIM are related to the topic of vaccination and the misconceptions surrounding it. The TWEET critiques a belief that is likely based on misinformation, while the CLAIM presents a specific example of such misinformation.\n",
            "\n",
            "3. **Degree of Relation**:\n",
            "   - The TWEET directly addresses the absurdity of the CLAIM, indicating that they are closely related. The TWEET serves as a commentary on the type of claims that circulate regarding vaccinations, including the one made in the CLAIM.\n",
            "\n",
            "Based on this analysis, I would rate the relationship between TWEET and CLAIM as a **4**. They are closely related, as the TWEET critiques the very notion presented in the CLAIM, but they are not identical in nature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can be creative,\n",
        "- but also remember not to rely too much on them because they tend to err\n",
        "- for annotation and classification tasks, I recommend you to carefully compare the results with different methods\n",
        "- for generative tasks, at least read the results for yourselves."
      ],
      "metadata": {
        "id": "tSO_7_cl89cv"
      },
      "id": "tSO_7_cl89cv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# On Your Own\n",
        "- Try to Prompt-Engineer the task you want to try out!"
      ],
      "metadata": {
        "id": "47CLqyQ28MFB"
      },
      "id": "47CLqyQ28MFB"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}